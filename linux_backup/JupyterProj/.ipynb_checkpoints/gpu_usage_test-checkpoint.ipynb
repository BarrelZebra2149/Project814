{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611e6d6-ae6f-4e03-83b4-944f12abf40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import multiprocessing\n",
    "from collections import Counter\n",
    "from deap import base, creator, tools\n",
    "import torch\n",
    "\n",
    "# Set multiprocessing start method to 'spawn' for CUDA compatibility\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        multiprocessing.set_start_method('spawn')\n",
    "    except RuntimeError:\n",
    "        pass  # already set\n",
    "\n",
    "# --- Device setup (CUDA is guaranteed) ---\n",
    "DEVICE = 'cuda'\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# --- Grid constants ---\n",
    "IND_ROWS = 8\n",
    "IND_COLS = 14\n",
    "IND_SIZE = IND_ROWS * IND_COLS\n",
    "INT_MIN, INT_MAX = 0, 9\n",
    "FILENAME = 'best_output_double.txt'\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0, 1.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# --- PyTorch helpers ---\n",
    "DELTAS = torch.tensor([\n",
    "    [-1, -1], [-1, 0], [-1, 1],\n",
    "    [0, -1],          [0, 1],\n",
    "    [1, -1], [1, 0], [1, 1]\n",
    "], dtype=torch.long, device=DEVICE)\n",
    "\n",
    "def positions_per_digit(grid_t):\n",
    "    pos = {}\n",
    "    for d in range(10):\n",
    "        rs, cs = torch.nonzero(grid_t == d, as_tuple=True)\n",
    "        if len(rs) > 0:\n",
    "            pos[d] = torch.stack([rs, cs], dim=1)\n",
    "    return pos\n",
    "\n",
    "def batch_has_path_torch(grid_np, numbers, precomputed_pos_dict=None):\n",
    "    if not numbers:\n",
    "        return np.array([], dtype=int)\n",
    "\n",
    "    grid_t = torch.from_numpy(grid_np.astype(np.int32)).to(DEVICE)\n",
    "    pos_dict = precomputed_pos_dict if precomputed_pos_dict is not None else positions_per_digit(grid_t)\n",
    "\n",
    "    results = torch.zeros(len(numbers), dtype=torch.int32, device=DEVICE)\n",
    "\n",
    "    for i, n_val in enumerate(numbers):\n",
    "        if n_val <= 0:\n",
    "            results[i] = 1 if (n_val == 0 and 0 in pos_dict) else 0\n",
    "            continue\n",
    "\n",
    "        str_n = str(n_val)\n",
    "        digits = torch.tensor([int(d) for d in str_n], device=DEVICE)\n",
    "        len_path = len(digits)\n",
    "\n",
    "        first_d = digits[0].item()\n",
    "        if first_d not in pos_dict or len(pos_dict[first_d]) == 0:\n",
    "            continue\n",
    "\n",
    "        if len_path == 1:\n",
    "            results[i] = 1\n",
    "            continue\n",
    "\n",
    "        visited = torch.zeros_like(grid_t, dtype=torch.bool)\n",
    "        current_front = pos_dict[first_d].clone()\n",
    "        visited[current_front[:, 0], current_front[:, 1]] = True\n",
    "\n",
    "        found = False\n",
    "        for depth in range(1, len_path):\n",
    "            next_d = digits[depth].item()\n",
    "            if next_d not in pos_dict:\n",
    "                break\n",
    "\n",
    "            r = current_front[:, 0][:, None] + DELTAS[:, 0][None, :]\n",
    "            c = current_front[:, 1][:, None] + DELTAS[:, 1][None, :]\n",
    "            expanded_r = r.flatten()\n",
    "            expanded_c = c.flatten()\n",
    "\n",
    "            valid = ((expanded_r >= 0) & (expanded_r < IND_ROWS) &\n",
    "                     (expanded_c >= 0) & (expanded_c < IND_COLS))\n",
    "            nr = expanded_r[valid]\n",
    "            nc = expanded_c[valid]\n",
    "\n",
    "            if len(nr) == 0:\n",
    "                break\n",
    "\n",
    "            is_next = (grid_t[nr, nc] == next_d)\n",
    "            not_visited = ~visited[nr, nc]\n",
    "            new_front_mask = is_next & not_visited\n",
    "\n",
    "            if not new_front_mask.any():\n",
    "                break\n",
    "\n",
    "            new_r = nr[new_front_mask]\n",
    "            new_c = nc[new_front_mask]\n",
    "            current_front = torch.stack([new_r, new_c], dim=1)\n",
    "\n",
    "            visited[new_r, new_c] = True\n",
    "\n",
    "            if depth == len_path - 1:\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if found:\n",
    "            results[i] = 1\n",
    "\n",
    "    return results.cpu().numpy()\n",
    "\n",
    "# --- Global precomputation of representatives (1~10000, reverse duplicates removed) ---\n",
    "REPRESENTATIVES = []\n",
    "PAIR_DICT = {}  # rep -> list of covered numbers (forward + valid reverse)\n",
    "\n",
    "seen = set()\n",
    "for n in range(1, 10001):\n",
    "    if n in seen:\n",
    "        continue\n",
    "\n",
    "    rev_str = str(n)[::-1]\n",
    "    rev_n = int(rev_str) if not rev_str.startswith('0') else None\n",
    "\n",
    "    covered = [n]\n",
    "    if rev_n is not None and rev_n != n:\n",
    "        covered.append(rev_n)\n",
    "        seen.add(rev_n)\n",
    "\n",
    "    seen.add(n)\n",
    "    REPRESENTATIVES.append(n)\n",
    "    PAIR_DICT[n] = covered\n",
    "\n",
    "print(f\"Precomputed {len(REPRESENTATIVES)} representatives for 1~10000 (reverse duplicates eliminated)\")\n",
    "\n",
    "# --- GPU-accelerated evaluation function ---\n",
    "def eval_814_heuristic(individual):\n",
    "    grid_np = np.array(individual).reshape(IND_ROWS, IND_COLS)\n",
    "    MAX_N = 50000\n",
    "\n",
    "    grid_t = torch.from_numpy(grid_np.astype(np.int32)).to(DEVICE)\n",
    "    pos_dict = positions_per_digit(grid_t)  # precompute once per individual\n",
    "\n",
    "    # One big batch for all 1~10000 representatives\n",
    "    has_array = batch_has_path_torch(grid_np, REPRESENTATIVES, precomputed_pos_dict=pos_dict)\n",
    "\n",
    "    found_set = set()\n",
    "    for rep, h in zip(REPRESENTATIVES, has_array):\n",
    "        if h == 1:\n",
    "            found_set.update(PAIR_DICT[rep])\n",
    "\n",
    "    # Compute current_score up to 10000\n",
    "    current_score = 0\n",
    "    for k in range(1, 10001):\n",
    "        if k in found_set:\n",
    "            current_score = k\n",
    "        else:\n",
    "            current_score = k - 1\n",
    "            break\n",
    "    else:\n",
    "        # All 1~10000 found → continue to higher numbers\n",
    "        n = 10001\n",
    "        batch_size = 1000\n",
    "        while n < MAX_N:\n",
    "            end = min(n + batch_size, MAX_N)\n",
    "            batch_nums = []\n",
    "            for cand in range(n, end):\n",
    "                rev_str = str(cand)[::-1]\n",
    "                rev_cand = int(rev_str) if not rev_str.startswith('0') else None\n",
    "                if cand in found_set or (rev_cand is not None and rev_cand in found_set):\n",
    "                    found_set.add(cand)\n",
    "                    if rev_cand is not None:\n",
    "                        found_set.add(rev_cand)\n",
    "                    current_score = cand\n",
    "                    continue\n",
    "                batch_nums.append(cand)\n",
    "\n",
    "            if batch_nums:\n",
    "                has = batch_has_path_torch(grid_np, batch_nums, precomputed_pos_dict=pos_dict)\n",
    "                i = 0\n",
    "                broke = False\n",
    "                for cand in range(n, end):\n",
    "                    if cand in found_set:\n",
    "                        continue\n",
    "                    h = has[i]\n",
    "                    i += 1\n",
    "                    if h == 1:\n",
    "                        rev_str = str(cand)[::-1]\n",
    "                        rev_cand = int(rev_str) if not rev_str.startswith('0') else None\n",
    "                        found_set.add(cand)\n",
    "                        if rev_cand is not None:\n",
    "                            found_set.add(rev_cand)\n",
    "                        current_score = cand\n",
    "                    else:\n",
    "                        current_score = cand - 1\n",
    "                        broke = True\n",
    "                        break\n",
    "                if broke:\n",
    "                    break\n",
    "            else:\n",
    "                current_score = end - 1\n",
    "\n",
    "            n = end\n",
    "        else:\n",
    "            current_score = MAX_N - 1\n",
    "\n",
    "    # Formable count: exact count of 1000~9999 in found_set (covered by representatives batch)\n",
    "    formable_count = sum(1 for num in range(1000, 10000) if num in found_set)\n",
    "\n",
    "    return float(current_score), float(formable_count)\n",
    "\n",
    "# Register the accelerated evaluate\n",
    "toolbox.register(\"evaluate\", eval_814_heuristic)\n",
    "\n",
    "# ────────────────────────────────────────────────\n",
    "# The rest of your original code (unchanged)\n",
    "# ────────────────────────────────────────────────\n",
    "def custom_mate(ind1, ind2):\n",
    "    grid1 = np.array(ind1).reshape(IND_ROWS, IND_COLS)\n",
    "    grid2 = np.array(ind2).reshape(IND_ROWS, IND_COLS)\n",
    "    s_y = random.randint(0, IND_ROWS - 1)\n",
    "    e_y = random.randint(s_y + 1, IND_ROWS)\n",
    "    s_x = random.randint(0, IND_COLS - 1)\n",
    "    e_x = random.randint(s_x + 1, IND_COLS)\n",
    "    temp = grid1[s_y:e_y, s_x:e_x].copy()\n",
    "    grid1[s_y:e_y, s_x:e_x] = grid2[s_y:e_y, s_x:e_x]\n",
    "    grid2[s_y:e_y, s_x:e_x] = temp\n",
    "    ind1[:] = grid1.ravel().tolist()\n",
    "    ind2[:] = grid2.ravel().tolist()\n",
    "    return ind1, ind2\n",
    "\n",
    "def custom_mutate(individual, indpb=0.05):\n",
    "    if random.random() < 0.5:\n",
    "        tools.mutUniformInt(individual, low=0, up=9, indpb=indpb)\n",
    "    else:\n",
    "        digits = list(range(10))\n",
    "        random.shuffle(digits)\n",
    "        a, b = digits[0], digits[1]\n",
    "        for i in range(len(individual)):\n",
    "            if individual[i] == a:\n",
    "                individual[i] = b\n",
    "            elif individual[i] == b:\n",
    "                individual[i] = a\n",
    "    return individual,\n",
    "\n",
    "toolbox.register(\"mate\", custom_mate)\n",
    "toolbox.register(\"mutate\", custom_mutate, indpb=0.05)\n",
    "\n",
    "def _assign_crowding_dist_fallback(front):\n",
    "    if not front:\n",
    "        return\n",
    "    if len(front) <= 2:\n",
    "        for ind in front:\n",
    "            ind.crowding_dist = float(\"inf\")\n",
    "        return\n",
    "    for ind in front:\n",
    "        ind.crowding_dist = 0.0\n",
    "    nobj = len(front[0].fitness.values)\n",
    "    for m in range(nobj):\n",
    "        front.sort(key=lambda ind: ind.fitness.values[m])\n",
    "        front[0].crowding_dist = float(\"inf\")\n",
    "        front[-1].crowding_dist = float(\"inf\")\n",
    "        fmin = front[0].fitness.values[m]\n",
    "        fmax = front[-1].fitness.values[m]\n",
    "        denom = fmax - fmin\n",
    "        if denom == 0:\n",
    "            continue\n",
    "        for i in range(1, len(front) - 1):\n",
    "            prev_f = front[i - 1].fitness.values[m]\n",
    "            next_f = front[i + 1].fitness.values[m]\n",
    "            front[i].crowding_dist += (next_f - prev_f) / denom\n",
    "\n",
    "def update_crowding(population):\n",
    "    fronts = tools.sortNondominated(population, k=len(population), first_front_only=False)\n",
    "    assign = None\n",
    "    if hasattr(tools, \"emo\") and hasattr(tools.emo, \"assignCrowdingDist\"):\n",
    "        assign = tools.emo.assignCrowdingDist\n",
    "    for front in fronts:\n",
    "        if assign is not None:\n",
    "            assign(front)\n",
    "        else:\n",
    "            _assign_crowding_dist_fallback(front)\n",
    "\n",
    "toolbox.register(\"select\", tools.selTournamentDCD)\n",
    "toolbox.register(\"attr_int\", random.randint, INT_MIN, INT_MAX)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_int, IND_SIZE)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "def load_previous_best():\n",
    "    loaded = []\n",
    "    protected = None\n",
    "    if os.path.exists(FILENAME):\n",
    "        with open(FILENAME, 'r') as f:\n",
    "            valid_lines = [line.strip() for line in f if len(line.strip()) == 14 and line.strip().isdigit()]\n",
    "        for block_start in range(0, len(valid_lines), 8):\n",
    "            if block_start + 7 >= len(valid_lines): break\n",
    "            block = valid_lines[block_start:block_start + 8]\n",
    "            ind_list = []\n",
    "            for row in block:\n",
    "                ind_list.extend(int(d) for d in row)\n",
    "            if len(ind_list) == IND_SIZE:\n",
    "                ind = creator.Individual(ind_list)\n",
    "                if block_start == 0:\n",
    "                    protected = ind\n",
    "                else:\n",
    "                    loaded.append(ind)\n",
    "    return protected, loaded\n",
    "\n",
    "def main():\n",
    "    protected, loaded = load_previous_best()\n",
    "    pop = []\n",
    "    if protected: pop.append(protected)\n",
    "    pop.extend(loaded)\n",
    "    TARGET_POP = 300\n",
    "    if len(pop) < TARGET_POP:\n",
    "        pop.extend(toolbox.population(n=TARGET_POP - len(pop)))\n",
    "    pop = pop[:TARGET_POP]\n",
    "\n",
    "    # Serial evaluation\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    update_crowding(pop)\n",
    "\n",
    "    CXPB, MUTPB = 0.5, 0.2\n",
    "    NGEN = 100\n",
    "    best_current_score = 0.0\n",
    "    best_ind = None\n",
    "    for g in range(1, NGEN + 1):\n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < CXPB:\n",
    "                toolbox.mate(child1, child2)\n",
    "                del child1.fitness.values, child2.fitness.values\n",
    "        for mutant in offspring:\n",
    "            if random.random() < MUTPB:\n",
    "                toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = list(map(toolbox.evaluate, invalid_ind))\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "        pop[:] = offspring\n",
    "        update_crowding(pop)\n",
    "        pop_max_v = [ind.fitness.values[0] for ind in pop]\n",
    "        current_max = max(pop_max_v)\n",
    "        if current_max > best_current_score:\n",
    "            best_current_score = current_max\n",
    "            best_ind = max(pop, key=lambda ind: ind.fitness.values[0])\n",
    "        if g % 1 == 0:\n",
    "            formable = [ind.fitness.values[1] for ind in pop]\n",
    "            sys.stdout.write(f\"--Generation {g}--\\n\")\n",
    "            sys.stdout.write(\n",
    "                f\"Current Score (1+)\\tMax: {current_max:>7.0f}\\tAvg: {sum(pop_max_v) / len(pop):>7.1f}\\n\")\n",
    "            sys.stdout.write(\n",
    "                f\"Formable Count\\tMax: {max(formable):>7.0f}\\tAvg: {sum(formable) / len(pop):>7.1f}\\n\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Evolution finished after {NGEN} generations\")\n",
    "\n",
    "    if best_ind is not None:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"GRID WITH THE HIGHEST CURRENT SCORE (consecutive from 1)\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Current Score : {best_current_score:.0f}\")\n",
    "        print(f\"Formable Count: {best_ind.fitness.values[1]:.0f}\")\n",
    "        grid = np.array(best_ind).reshape(IND_ROWS, IND_COLS)\n",
    "        for row in grid:\n",
    "            print(''.join(map(str, row)))\n",
    "        flat = list(best_ind)\n",
    "        counts = Counter(flat)\n",
    "        print(\"\\nDigit distribution:\", ' '.join(f\"{d}:{counts[d]}\" for d in range(10)))\n",
    "        with open(FILENAME, 'a') as f:\n",
    "            for row in grid:\n",
    "                f.write(''.join(map(str, row)) + '\\n')\n",
    "            f.write('\\n')\n",
    "        print(\"Highest current_score grid saved to file.\")\n",
    "    else:\n",
    "        print(\"No valid individuals found to save.\")\n",
    "\n",
    "    top3 = tools.selBest(pop, k=3)\n",
    "    for rank, ind in enumerate(top3, 1):\n",
    "        curr, form = ind.fitness.values\n",
    "        print(f\"\\nTop #{rank} Individual:\")\n",
    "        print(f\" Current consecutive score : {curr:>7.0f}\")\n",
    "        print(f\" Formable count (1000-9999): {form:>7.0f}\")\n",
    "        grid = np.array(ind).reshape(IND_ROWS, IND_COLS)\n",
    "        print(\" Grid:\")\n",
    "        for row in grid:\n",
    "            print(' ' + ''.join(map(str, row)))\n",
    "        flat = list(ind)\n",
    "        counts = Counter(flat)\n",
    "        print(\" Digit distribution:\", ' '.join(f\"{d}:{counts[d]}\" for d in range(10)))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    with open(FILENAME, 'a') as f:\n",
    "        grid = np.array(top3[0]).reshape(IND_ROWS, IND_COLS)\n",
    "        for row in grid:\n",
    "            f.write(''.join(map(str, row)) + '\\n')\n",
    "        f.write('\\n')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4686a5-dc8d-44ba-b6e9-76c695019206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
